{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = ['the woman is a wise queen',\n",
    "          'the man is a wise president',\n",
    "          'she is a pretty woman',\n",
    "          'he is a strong man',\n",
    "          'she is still young',\n",
    "          'he is very old',\n",
    "          'he is the current president of US',\n",
    "          'the prince is a son of the king',\n",
    "          'the princess is a daughter of the king',\n",
    "          'a prince is a young man',\n",
    "          'a princess is a young woman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 한문장씩 읽으면서 \" \" 으로 분류하여, 요소 추출.\n",
    "def function1(corpus):    \n",
    "    sentences = []\n",
    "    for sentence in corpus:\n",
    "        sentences.append(sentence.split())\n",
    "\n",
    "    window_size = 2 # q2) s의 의미를 적고 그에 맞게 변수명 변경하기\n",
    "\n",
    "    data = []\n",
    "    for sentence in sentences:\n",
    "        # 한문장씩 읽으면서 window size 기준으로 요소 추출하기.\n",
    "        for idx, word in enumerate(sentence):\n",
    "            # neighbor 가져오기. \n",
    "            for neighbor in sentence[max(idx - window_size, 0) : min(idx + window_size, len(sentence)) + 1] : \n",
    "                if neighbor != word:\n",
    "                    data.append([word, neighbor])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = function1(corpus)\n",
    "df = pd.DataFrame(data, columns = ['input', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>the</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>woman</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>woman</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>woman</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>is</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>is</td>\n",
       "      <td>wise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input  label\n",
       "0    the  woman\n",
       "1    the     is\n",
       "2  woman    the\n",
       "3  woman     is\n",
       "4  woman      a\n",
       "5     is    the\n",
       "6     is  woman\n",
       "7     is      a\n",
       "8     is   wise\n",
       "9      a  woman"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 2)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q3) unique values 뽑아내기\n",
    "def function2(corpus):\n",
    "    words = []\n",
    "    for text in corpus:\n",
    "        for word in text.split(' '):\n",
    "            words.append(word)\n",
    "    words = set(words)\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'son', 'wise', 'still', 'the', 'young', 'man', 'daughter', 'is', 'US', 'prince', 'strong', 'pretty', 'of', 'she', 'a', 'current', 'princess', 'he', 'president', 'queen', 'woman', 'very', 'old', 'king'}\n"
     ]
    }
   ],
   "source": [
    "words = function2(corpus)\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q4) one_hot_encoding 하기 위한 단어별 인덱스 부여\n",
    "# 단어 인덱스를 이용하여, 나중에 0000000 배열에 그 인덱스에 1을 넣어주면\n",
    "# one_hot_encoding 자동 생성! \n",
    "def function3(words):\n",
    "    word2int = {}\n",
    "    for i,word in enumerate(words):\n",
    "        word2int[word] = i\n",
    "    return word2int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'son': 0, 'wise': 1, 'still': 2, 'the': 3, 'young': 4, 'man': 5, 'daughter': 6, 'is': 7, 'US': 8, 'prince': 9, 'strong': 10, 'pretty': 11, 'of': 12, 'she': 13, 'a': 14, 'current': 15, 'princess': 16, 'he': 17, 'president': 18, 'queen': 19, 'woman': 20, 'very': 21, 'old': 22, 'king': 23}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "word2int = function3(words)\n",
    "print(word2int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# q5) 앞서 말한 word unique index에 1을 넣어줌으로써, one hot encoding\n",
    "def function4(word_index, ONE_HOT_DIM):\n",
    "    one_hot_encoding = np.zeros(ONE_HOT_DIM)\n",
    "    one_hot_encoding[word_index] = 1\n",
    "    return one_hot_encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# q6) Word2Vec을 tensorflow로 구현한 코드에서 ? 부분을 올바르게 채워넣기\n",
    "# Skip Gram\n",
    "# cross entropy 참고\n",
    "# https://ratsgo.github.io/deep%20learning/2017/10/02/softmax/\n",
    "# https://kevinthegrey.tistory.com/123"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sora\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "Y_train [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "ONE_HOT_DIM = len(words)\n",
    "\n",
    "X = [] # input word\n",
    "Y = [] # target word\n",
    "\n",
    "# window size고려해서 중심 단어 기준으로 주변 단어 추출된 df\n",
    "# skip grame을 하기 위한 전처리 단계된 것이 df이다.\n",
    "for x, y in zip(df['input'], df['label']):\n",
    "    X.append(function4(word2int[x], ONE_HOT_DIM))\n",
    "    Y.append(function4(word2int[y], ONE_HOT_DIM))\n",
    "\n",
    "# convert X,Y to numpy arrays\n",
    "X_train = np.asarray(X)\n",
    "print(\"X_train\",X_train)\n",
    "Y_train = np.asarray(Y)\n",
    "print(\"Y_train\",Y_train)\n",
    "\n",
    "# placeholders for X_train and Y_train\n",
    "# 해당되는 단어의 위치값만 1인 one_hot_dim 차원의 x\n",
    "x = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "# y는 window size로 추출된 단어 짝?\n",
    "y_label = tf.placeholder(tf.float32, shape=(None, ONE_HOT_DIM))\n",
    "\n",
    "# embedding dimension\n",
    "EMBEDDING_DIM = 2\n",
    "\n",
    "# hidden layer : represent word vector eventually\n",
    "# x는 one hot encoding으로 되어있음으로 1과 곱해지는 값이 결국 단어 vector가 된다. \n",
    "W1 = tf.Variable(tf.random_normal([ONE_HOT_DIM, EMBEDDING_DIM]))\n",
    "b1 = tf.Variable(tf.random_normal([1]))\n",
    "hidden_layer = tf.add(tf.matmul(x,W1), b1)\n",
    "\n",
    "# output layer\n",
    "# 출력 layer로 넘어 가기 위해 hidden node의 사이즈를 one_hot_dim으로 맞춰준다. \n",
    "W2 = tf.Variable(tf.random_normal([EMBEDDING_DIM, ONE_HOT_DIM]))\n",
    "b2 = tf.Variable(tf.random_normal([1]))\n",
    "output = tf.nn.softmax(tf.add( tf.matmul(hidden_layer, W2), b2))\n",
    "\n",
    "# loss function : cross entropy\n",
    "loss = tf.reduce_mean(-tf.reduce_sum(y_label * tf.log(output), axis=[1]))\n",
    "\n",
    "# training\n",
    "train = tf.train.GradientDescentOptimizer(0.05).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration 0 loss is :  5.943717\n",
      "iteration 2000 loss is :  2.5070548\n",
      "iteration 4000 loss is :  2.4539084\n",
      "iteration 6000 loss is :  2.4328113\n",
      "iteration 8000 loss is :  2.4196827\n"
     ]
    }
   ],
   "source": [
    "# 모델\n",
    "sess = tf.Session()\n",
    "init = tf.global_variables_initializer()\n",
    "sess.run(init) \n",
    "# 10000번 epoch\n",
    "iteration = 10000\n",
    "for i in range(iteration):\n",
    "    # input : X_train which is one hot encoded word\n",
    "    # label : Y_train which is one hot encoded neighbor word\n",
    "    sess.run(train, feed_dict={x: X_train, y_label: Y_train})\n",
    "    if i % 2000 == 0:\n",
    "        print('iteration '+ str(i) +' loss is : ', sess.run(loss, feed_dict={x: X_train, y_label: Y_train}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.0978762 , -2.1517684 ],\n",
       "       [-0.1036793 , -1.490266  ],\n",
       "       [ 0.23846161, -1.1268069 ],\n",
       "       [ 0.19145775, -0.5982637 ],\n",
       "       [ 0.6188953 , -1.4304115 ],\n",
       "       [-0.6755203 , -1.8086963 ],\n",
       "       [-1.2464038 , -2.448387  ],\n",
       "       [-0.2885266 , -0.74118865],\n",
       "       [-1.2662954 , -0.46191442],\n",
       "       [-0.9836996 , -3.3101535 ],\n",
       "       [ 0.41692686, -1.5898042 ],\n",
       "       [ 0.5206425 , -1.5247324 ],\n",
       "       [-1.1570241 , -0.02426124],\n",
       "       [ 0.3532982 , -1.6635354 ],\n",
       "       [ 0.584262  , -0.7910292 ],\n",
       "       [-0.8408792 , -1.2953045 ],\n",
       "       [-0.95394766, -3.2238941 ],\n",
       "       [-0.2187311 , -2.0093484 ],\n",
       "       [-1.817772  , -0.04998982],\n",
       "       [-0.8047435 , -1.2670597 ],\n",
       "       [-0.6581907 , -1.7914922 ],\n",
       "       [ 0.3132609 , -0.47521514],\n",
       "       [ 0.17851496, -1.2807887 ],\n",
       "       [-3.5373764 , -0.78490555]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the hidden layer (W1 + b1) -> look up table\n",
    "vectors = sess.run(W1 + b1)\n",
    "vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>son</td>\n",
       "      <td>-1.097876</td>\n",
       "      <td>-2.151768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wise</td>\n",
       "      <td>-0.103679</td>\n",
       "      <td>-1.490266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>still</td>\n",
       "      <td>0.238462</td>\n",
       "      <td>-1.126807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>the</td>\n",
       "      <td>0.191458</td>\n",
       "      <td>-0.598264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>young</td>\n",
       "      <td>0.618895</td>\n",
       "      <td>-1.430411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>man</td>\n",
       "      <td>-0.675520</td>\n",
       "      <td>-1.808696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>daughter</td>\n",
       "      <td>-1.246404</td>\n",
       "      <td>-2.448387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>is</td>\n",
       "      <td>-0.288527</td>\n",
       "      <td>-0.741189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>US</td>\n",
       "      <td>-1.266295</td>\n",
       "      <td>-0.461914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>prince</td>\n",
       "      <td>-0.983700</td>\n",
       "      <td>-3.310153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>strong</td>\n",
       "      <td>0.416927</td>\n",
       "      <td>-1.589804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>pretty</td>\n",
       "      <td>0.520643</td>\n",
       "      <td>-1.524732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of</td>\n",
       "      <td>-1.157024</td>\n",
       "      <td>-0.024261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>she</td>\n",
       "      <td>0.353298</td>\n",
       "      <td>-1.663535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>0.584262</td>\n",
       "      <td>-0.791029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>current</td>\n",
       "      <td>-0.840879</td>\n",
       "      <td>-1.295305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>princess</td>\n",
       "      <td>-0.953948</td>\n",
       "      <td>-3.223894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>he</td>\n",
       "      <td>-0.218731</td>\n",
       "      <td>-2.009348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>president</td>\n",
       "      <td>-1.817772</td>\n",
       "      <td>-0.049990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>queen</td>\n",
       "      <td>-0.804744</td>\n",
       "      <td>-1.267060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>woman</td>\n",
       "      <td>-0.658191</td>\n",
       "      <td>-1.791492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>very</td>\n",
       "      <td>0.313261</td>\n",
       "      <td>-0.475215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>old</td>\n",
       "      <td>0.178515</td>\n",
       "      <td>-1.280789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>king</td>\n",
       "      <td>-3.537376</td>\n",
       "      <td>-0.784906</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word        x1        x2\n",
       "0         son -1.097876 -2.151768\n",
       "1        wise -0.103679 -1.490266\n",
       "2       still  0.238462 -1.126807\n",
       "3         the  0.191458 -0.598264\n",
       "4       young  0.618895 -1.430411\n",
       "5         man -0.675520 -1.808696\n",
       "6    daughter -1.246404 -2.448387\n",
       "7          is -0.288527 -0.741189\n",
       "8          US -1.266295 -0.461914\n",
       "9      prince -0.983700 -3.310153\n",
       "10     strong  0.416927 -1.589804\n",
       "11     pretty  0.520643 -1.524732\n",
       "12         of -1.157024 -0.024261\n",
       "13        she  0.353298 -1.663535\n",
       "14          a  0.584262 -0.791029\n",
       "15    current -0.840879 -1.295305\n",
       "16   princess -0.953948 -3.223894\n",
       "17         he -0.218731 -2.009348\n",
       "18  president -1.817772 -0.049990\n",
       "19      queen -0.804744 -1.267060\n",
       "20      woman -0.658191 -1.791492\n",
       "21       very  0.313261 -0.475215\n",
       "22        old  0.178515 -1.280789\n",
       "23       king -3.537376 -0.784906"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_df = pd.DataFrame(vectors, columns = ['x1', 'x2'])\n",
    "w2v_df['word'] = words\n",
    "w2v_df = w2v_df[['word', 'x1', 'x2']]\n",
    "w2v_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# word와 두개의 좌표값 불러오기 \n",
    "for word, x1, x2 in zip(w2v_df['word'], w2v_df['x1'], w2v_df['x2']):\n",
    "    ax.annotate(word, (x1,x2 ))\n",
    "    \n",
    "PADDING = 1.0\n",
    "#  최소, 최대값으로 그래프 폭 결정.\n",
    "# PADDING은 여유값 설정 . \n",
    "x1_axis_min = np.amin(vectors, axis=0)[0] - PADDING\n",
    "x2_axis_min = np.amin(vectors, axis=0)[1] - PADDING\n",
    "x1_axis_max = np.amax(vectors, axis=0)[0] + PADDING\n",
    "x2_axis_max = np.amax(vectors, axis=0)[1] + PADDING\n",
    " \n",
    "plt.xlim(x1_axis_min,x1_axis_max)\n",
    "plt.ylim(x2_axis_min,x2_axis_max)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
